\section{Essential ML ideas}
\smallskip \hrule height 2pt \smallskip

\begin{itemize}
	\item Never ever \underline{ever} touch the test set
	\item You know you are overfitting when there is a big test between train and test results.  E.g. metric of percent wrong. 
	\item Need to be comfortable taking a hit on fitting accuracy if you can get a benefit on the result.
	\item Bias vs variance trade-off.  
		High bias when the model is too simple \& doesn't fit the data well.  
		High variance is when small changes to the data set lead to large solution changes. 
	\item If features are non discriminative in the beginning, they don't work for any classifier.  % week 4 reminder
	\item Your feature vector often has a smaller dimension that the feature space.    % week 4, Friday. 
		If you have too long of a feature vector, you may get overfitting. 
	\item You need to prevent the optimizer from getting an easy way out.  % week 7 audio
	\item Whenever we are building a discriminative classifier, 
        		we should not expect it to reason about things it has never seen before
    		You can't classify on something that has only seen + points. 
    		The classifier needs to see some + and some - or it will fail miserably.   % week 8 audio
	\item We should always avoid making hard decisions early.  % week 8 audo. 
		 E.g. don't put a lot of trust in classifiers early on in bagging. 
\end{itemize}

You can do $l_2$ normalization for a feature vector to get a unit vector:   % week 6 audio. 
	Convert $x$ to $\hat{x}$ so that if you form $||\hat{x}||_2^2 = 1$
	Can also do $l_1$  
